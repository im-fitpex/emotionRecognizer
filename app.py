import os
import torch
import librosa
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
from src.model import EmotionCNN   # –µ—Å–ª–∏ model.py –≤ –ø–∞–ø–∫–µ src

# –≠–º–æ—Ü–∏–∏
EMOTIONS = ["neutral","calm","happy","sad","angry","fearful","disgust","surprised"]
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# —Ñ–∏–∫—Å –¥–ª–∏–Ω—ã –∫–∞–∫ –≤ dataset.py
max_len = 150

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
model = EmotionCNN(num_classes=8, max_len=max_len).to(device)
model.load_state_dict(torch.load("models/emotion_cnn.pth", map_location=device))
model.eval()

def predict(file):
    y, sr = librosa.load(file, sr=16000)
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)

    # –ø–∞–¥–¥–∏–Ω–≥ –∏–ª–∏ –æ–±—Ä–µ–∑–∫–∞
    if mfcc.shape[1] < max_len:
        pad_width = max_len - mfcc.shape[1]
        mfcc = np.pad(mfcc, ((0,0),(0,pad_width)), mode="constant")
    else:
        mfcc = mfcc[:, :max_len]

    X = torch.tensor(mfcc).unsqueeze(0).unsqueeze(0).float().to(device)

    with torch.no_grad():
        outputs = model(X)
        probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]
        _, pred = torch.max(outputs, 1)

    return EMOTIONS[pred.item()], mfcc, probs

# ---------------- GUI ----------------
st.title("üé§ Emotion Recognition from Voice")
st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ .wav —Ñ–∞–π–ª –∏ –ø–æ–ª—É—á–∏—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—É—é —ç–º–æ—Ü–∏—é + MFCC –≥—Ä–∞—Ñ–∏–∫")

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª", type=["wav"])

if uploaded_file is not None:
    # –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–Ω–∏–µ
    st.audio(uploaded_file, format="audio/wav")

    # –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    with open("temp.wav", "wb") as f:
        f.write(uploaded_file.getbuffer())

    # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    emotion, mfcc, probs = predict("temp.wav")

    # –≤—ã–≤–æ–¥ —ç–º–æ—Ü–∏–∏
    st.success(f"üß† –û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è —ç–º–æ—Ü–∏—è: **{emotion}**")

    # MFCC –≥—Ä–∞—Ñ–∏–∫
    fig, ax = plt.subplots(figsize=(8, 4))
    img = ax.imshow(mfcc, aspect="auto", origin="lower")
    ax.set_title(f"MFCC (Predicted: {emotion})")
    fig.colorbar(img, ax=ax)
    st.pyplot(fig)

    # –ë–∞—Ä—á–∞—Ä—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
    st.subheader("üìä –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –≤—Å–µ–º —ç–º–æ—Ü–∏—è–º")
    st.bar_chart({EMOTIONS[i]: probs[i] for i in range(len(EMOTIONS))})

    # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    os.remove("temp.wav")